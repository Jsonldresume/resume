{"ast":null,"code":"'use strict';\n\nvar assign = require('../constant/assign.js');\n\nvar chunkedSplice = require('./chunked-splice.js');\n\nvar chunkedPush = require('./chunked-push.js');\n\nvar miniflat = require('./miniflat.js');\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js');\n\nvar shallow = require('./shallow.js');\n\nvar resolveAll = require('./resolve-all.js');\n\nvar serializeChunks = require('./serialize-chunks.js');\n\nvar sliceChunks = require('./slice-chunks.js'); // Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesn’t receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\n\n\nfunction createTokenizer(parser, initialize, from) {\n  var point = from ? shallow(from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  };\n  var columnStart = {};\n  var resolveAllConstructs = [];\n  var chunks = [];\n  var stack = [];\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    })\n  }; // State and tools for resolving and serializing.\n\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  }; // The state function.\n\n  var state = initialize.tokenize.call(context, effects); // Track which character we expect to be consumed, to catch bugs.\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  } // Store where we are in the input stream.\n\n\n  point._index = 0;\n  point._bufferIndex = -1;\n  return context;\n\n  function write(slice) {\n    chunks = chunkedPush(chunks, slice);\n    main(); // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n\n    addResult(initialize, 0); // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  } //\n  // Tools.\n  //\n\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token));\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  function now() {\n    return shallow(point);\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n\n  function main() {\n    var chunkIndex;\n    var chunk;\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index]; // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  } // Deal with one code.\n\n\n  function go(code) {\n    state = state(code);\n  } // Move a character forward.\n\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    } // Not in a string chunk.\n\n\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++; // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    } // Expose the previous character.\n\n\n    context.previous = code; // Mark as consumed.\n  } // Start a token.\n\n\n  function enter(type, fields) {\n    var token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  } // Stop a token.\n\n\n  function exit(type) {\n    var token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  } // Use results.\n\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  } // Discard results.\n\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore();\n  } // Factory to attempt/check/interrupt.\n\n\n  function constructFactory(onreturn, fields) {\n    return hook; // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs;\n      var constructIndex;\n      var currentConstruct;\n      var info;\n      return constructs.tokenize || 'length' in constructs ? handleListOfConstructs(miniflat(constructs)) : handleMapOfConstructs;\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(constructs.null ?\n          /* c8 ignore next */\n          miniflat(constructs[code]).concat(miniflat(constructs.null)) : constructs[code])(code);\n        }\n\n        return bogusState(code);\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        return handleConstruct(list[constructIndex]);\n      }\n\n      function handleConstruct(construct) {\n        return start;\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          if (construct.name && context.parser.constructs.disable.null.indexOf(construct.name) > -1) {\n            return nok();\n          }\n\n          return construct.tokenize.call(fields ? assign({}, context, fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      function ok(code) {\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      function nok(code) {\n        info.restore();\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n\n        return bogusState;\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct);\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  function store() {\n    var startPoint = now();\n    var startPrevious = context.previous;\n    var startCurrentConstruct = context.currentConstruct;\n    var startEventsIndex = context.events.length;\n    var startStack = Array.from(stack);\n    return {\n      restore: restore,\n      from: startEventsIndex\n    };\n\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\nmodule.exports = createTokenizer;","map":{"version":3,"sources":["D:/github/jsonldresume/my-app/node_modules/micromark/dist/util/create-tokenizer.js"],"names":["assign","require","chunkedSplice","chunkedPush","miniflat","markdownLineEnding","shallow","resolveAll","serializeChunks","sliceChunks","createTokenizer","parser","initialize","from","point","line","column","offset","columnStart","resolveAllConstructs","chunks","stack","effects","consume","enter","exit","attempt","constructFactory","onsuccessfulconstruct","check","onsuccessfulcheck","interrupt","lazy","context","previous","events","sliceStream","sliceSerialize","now","defineSkip","skip","write","state","tokenize","call","push","_index","_bufferIndex","slice","main","length","addResult","token","value","accountForPotentialSkip","chunkIndex","chunk","go","charCodeAt","code","type","fields","start","pop","end","construct","info","restore","onreturn","hook","constructs","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","handleListOfConstructs","handleMapOfConstructs","null","concat","list","handleConstruct","store","partial","name","disable","indexOf","nok","ok","resolve","resolveTo","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","Array","module","exports"],"mappings":"AAAA;;AAEA,IAAIA,MAAM,GAAGC,OAAO,CAAC,uBAAD,CAApB;;AACA,IAAIC,aAAa,GAAGD,OAAO,CAAC,qBAAD,CAA3B;;AACA,IAAIE,WAAW,GAAGF,OAAO,CAAC,mBAAD,CAAzB;;AACA,IAAIG,QAAQ,GAAGH,OAAO,CAAC,eAAD,CAAtB;;AACA,IAAII,kBAAkB,GAAGJ,OAAO,CAAC,sCAAD,CAAhC;;AACA,IAAIK,OAAO,GAAGL,OAAO,CAAC,cAAD,CAArB;;AACA,IAAIM,UAAU,GAAGN,OAAO,CAAC,kBAAD,CAAxB;;AACA,IAAIO,eAAe,GAAGP,OAAO,CAAC,uBAAD,CAA7B;;AACA,IAAIQ,WAAW,GAAGR,OAAO,CAAC,mBAAD,CAAzB,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASS,eAAT,CAAyBC,MAAzB,EAAiCC,UAAjC,EAA6CC,IAA7C,EAAmD;AACjD,MAAIC,KAAK,GAAGD,IAAI,GACZP,OAAO,CAACO,IAAD,CADK,GAEZ;AACEE,IAAAA,IAAI,EAAE,CADR;AAEEC,IAAAA,MAAM,EAAE,CAFV;AAGEC,IAAAA,MAAM,EAAE;AAHV,GAFJ;AAOA,MAAIC,WAAW,GAAG,EAAlB;AACA,MAAIC,oBAAoB,GAAG,EAA3B;AACA,MAAIC,MAAM,GAAG,EAAb;AACA,MAAIC,KAAK,GAAG,EAAZ;AAEA,MAAIC,OAAO,GAAG;AACZC,IAAAA,OAAO,EAAEA,OADG;AAEZC,IAAAA,KAAK,EAAEA,KAFK;AAGZC,IAAAA,IAAI,EAAEA,IAHM;AAIZC,IAAAA,OAAO,EAAEC,gBAAgB,CAACC,qBAAD,CAJb;AAKZC,IAAAA,KAAK,EAAEF,gBAAgB,CAACG,iBAAD,CALX;AAMZC,IAAAA,SAAS,EAAEJ,gBAAgB,CAACG,iBAAD,EAAoB;AAC7CC,MAAAA,SAAS,EAAE;AADkC,KAApB,CANf;AASZC,IAAAA,IAAI,EAAEL,gBAAgB,CAACG,iBAAD,EAAoB;AACxCE,MAAAA,IAAI,EAAE;AADkC,KAApB;AATV,GAAd,CAbiD,CAyB/C;;AAEF,MAAIC,OAAO,GAAG;AACZC,IAAAA,QAAQ,EAAE,IADE;AAEZC,IAAAA,MAAM,EAAE,EAFI;AAGZxB,IAAAA,MAAM,EAAEA,MAHI;AAIZyB,IAAAA,WAAW,EAAEA,WAJD;AAKZC,IAAAA,cAAc,EAAEA,cALJ;AAMZC,IAAAA,GAAG,EAAEA,GANO;AAOZC,IAAAA,UAAU,EAAEC,IAPA;AAQZC,IAAAA,KAAK,EAAEA;AARK,GAAd,CA3BiD,CAoC/C;;AAEF,MAAIC,KAAK,GAAG9B,UAAU,CAAC+B,QAAX,CAAoBC,IAApB,CAAyBX,OAAzB,EAAkCX,OAAlC,CAAZ,CAtCiD,CAsCM;;AAEvD,MAAIV,UAAU,CAACL,UAAf,EAA2B;AACzBY,IAAAA,oBAAoB,CAAC0B,IAArB,CAA0BjC,UAA1B;AACD,GA1CgD,CA0C/C;;;AAEFE,EAAAA,KAAK,CAACgC,MAAN,GAAe,CAAf;AACAhC,EAAAA,KAAK,CAACiC,YAAN,GAAqB,CAAC,CAAtB;AACA,SAAOd,OAAP;;AAEA,WAASQ,KAAT,CAAeO,KAAf,EAAsB;AACpB5B,IAAAA,MAAM,GAAGjB,WAAW,CAACiB,MAAD,EAAS4B,KAAT,CAApB;AACAC,IAAAA,IAAI,GAFgB,CAEb;;AAEP,QAAI7B,MAAM,CAACA,MAAM,CAAC8B,MAAP,GAAgB,CAAjB,CAAN,KAA8B,IAAlC,EAAwC;AACtC,aAAO,EAAP;AACD;;AAEDC,IAAAA,SAAS,CAACvC,UAAD,EAAa,CAAb,CAAT,CARoB,CAQK;;AAEzBqB,IAAAA,OAAO,CAACE,MAAR,GAAiB5B,UAAU,CAACY,oBAAD,EAAuBc,OAAO,CAACE,MAA/B,EAAuCF,OAAvC,CAA3B;AACA,WAAOA,OAAO,CAACE,MAAf;AACD,GA5DgD,CA4D/C;AACF;AACA;;;AAEA,WAASE,cAAT,CAAwBe,KAAxB,EAA+B;AAC7B,WAAO5C,eAAe,CAAC4B,WAAW,CAACgB,KAAD,CAAZ,CAAtB;AACD;;AAED,WAAShB,WAAT,CAAqBgB,KAArB,EAA4B;AAC1B,WAAO3C,WAAW,CAACW,MAAD,EAASgC,KAAT,CAAlB;AACD;;AAED,WAASd,GAAT,GAAe;AACb,WAAOhC,OAAO,CAACQ,KAAD,CAAd;AACD;;AAED,WAAS0B,IAAT,CAAca,KAAd,EAAqB;AACnBnC,IAAAA,WAAW,CAACmC,KAAK,CAACtC,IAAP,CAAX,GAA0BsC,KAAK,CAACrC,MAAhC;AACAsC,IAAAA,uBAAuB;AACxB,GA/EgD,CA+E/C;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,WAASL,IAAT,GAAgB;AACd,QAAIM,UAAJ;AACA,QAAIC,KAAJ;;AAEA,WAAO1C,KAAK,CAACgC,MAAN,GAAe1B,MAAM,CAAC8B,MAA7B,EAAqC;AACnCM,MAAAA,KAAK,GAAGpC,MAAM,CAACN,KAAK,CAACgC,MAAP,CAAd,CADmC,CACN;;AAE7B,UAAI,OAAOU,KAAP,KAAiB,QAArB,EAA+B;AAC7BD,QAAAA,UAAU,GAAGzC,KAAK,CAACgC,MAAnB;;AAEA,YAAIhC,KAAK,CAACiC,YAAN,GAAqB,CAAzB,EAA4B;AAC1BjC,UAAAA,KAAK,CAACiC,YAAN,GAAqB,CAArB;AACD;;AAED,eACEjC,KAAK,CAACgC,MAAN,KAAiBS,UAAjB,IACAzC,KAAK,CAACiC,YAAN,GAAqBS,KAAK,CAACN,MAF7B,EAGE;AACAO,UAAAA,EAAE,CAACD,KAAK,CAACE,UAAN,CAAiB5C,KAAK,CAACiC,YAAvB,CAAD,CAAF;AACD;AACF,OAbD,MAaO;AACLU,QAAAA,EAAE,CAACD,KAAD,CAAF;AACD;AACF;AACF,GAjHgD,CAiH/C;;;AAEF,WAASC,EAAT,CAAYE,IAAZ,EAAkB;AAChBjB,IAAAA,KAAK,GAAGA,KAAK,CAACiB,IAAD,CAAb;AACD,GArHgD,CAqH/C;;;AAEF,WAASpC,OAAT,CAAiBoC,IAAjB,EAAuB;AACrB,QAAItD,kBAAkB,CAACsD,IAAD,CAAtB,EAA8B;AAC5B7C,MAAAA,KAAK,CAACC,IAAN;AACAD,MAAAA,KAAK,CAACE,MAAN,GAAe,CAAf;AACAF,MAAAA,KAAK,CAACG,MAAN,IAAgB0C,IAAI,KAAK,CAAC,CAAV,GAAc,CAAd,GAAkB,CAAlC;AACAL,MAAAA,uBAAuB;AACxB,KALD,MAKO,IAAIK,IAAI,KAAK,CAAC,CAAd,EAAiB;AACtB7C,MAAAA,KAAK,CAACE,MAAN;AACAF,MAAAA,KAAK,CAACG,MAAN;AACD,KAToB,CASnB;;;AAEF,QAAIH,KAAK,CAACiC,YAAN,GAAqB,CAAzB,EAA4B;AAC1BjC,MAAAA,KAAK,CAACgC,MAAN;AACD,KAFD,MAEO;AACLhC,MAAAA,KAAK,CAACiC,YAAN,GADK,CACgB;;AAErB,UAAIjC,KAAK,CAACiC,YAAN,KAAuB3B,MAAM,CAACN,KAAK,CAACgC,MAAP,CAAN,CAAqBI,MAAhD,EAAwD;AACtDpC,QAAAA,KAAK,CAACiC,YAAN,GAAqB,CAAC,CAAtB;AACAjC,QAAAA,KAAK,CAACgC,MAAN;AACD;AACF,KApBoB,CAoBnB;;;AAEFb,IAAAA,OAAO,CAACC,QAAR,GAAmByB,IAAnB,CAtBqB,CAsBG;AACzB,GA9IgD,CA8I/C;;;AAEF,WAASnC,KAAT,CAAeoC,IAAf,EAAqBC,MAArB,EAA6B;AAC3B,QAAIT,KAAK,GAAGS,MAAM,IAAI,EAAtB;AACAT,IAAAA,KAAK,CAACQ,IAAN,GAAaA,IAAb;AACAR,IAAAA,KAAK,CAACU,KAAN,GAAcxB,GAAG,EAAjB;AACAL,IAAAA,OAAO,CAACE,MAAR,CAAeU,IAAf,CAAoB,CAAC,OAAD,EAAUO,KAAV,EAAiBnB,OAAjB,CAApB;AACAZ,IAAAA,KAAK,CAACwB,IAAN,CAAWO,KAAX;AACA,WAAOA,KAAP;AACD,GAvJgD,CAuJ/C;;;AAEF,WAAS3B,IAAT,CAAcmC,IAAd,EAAoB;AAClB,QAAIR,KAAK,GAAG/B,KAAK,CAAC0C,GAAN,EAAZ;AACAX,IAAAA,KAAK,CAACY,GAAN,GAAY1B,GAAG,EAAf;AACAL,IAAAA,OAAO,CAACE,MAAR,CAAeU,IAAf,CAAoB,CAAC,MAAD,EAASO,KAAT,EAAgBnB,OAAhB,CAApB;AACA,WAAOmB,KAAP;AACD,GA9JgD,CA8J/C;;;AAEF,WAASxB,qBAAT,CAA+BqC,SAA/B,EAA0CC,IAA1C,EAAgD;AAC9Cf,IAAAA,SAAS,CAACc,SAAD,EAAYC,IAAI,CAACrD,IAAjB,CAAT;AACD,GAlKgD,CAkK/C;;;AAEF,WAASiB,iBAAT,CAA2BmC,SAA3B,EAAsCC,IAAtC,EAA4C;AAC1CA,IAAAA,IAAI,CAACC,OAAL;AACD,GAtKgD,CAsK/C;;;AAEF,WAASxC,gBAAT,CAA0ByC,QAA1B,EAAoCP,MAApC,EAA4C;AAC1C,WAAOQ,IAAP,CAD0C,CAC9B;AACZ;;AAEA,aAASA,IAAT,CAAcC,UAAd,EAA0BC,WAA1B,EAAuCC,UAAvC,EAAmD;AACjD,UAAIC,gBAAJ;AACA,UAAIC,cAAJ;AACA,UAAIC,gBAAJ;AACA,UAAIT,IAAJ;AACA,aAAOI,UAAU,CAAC3B,QAAX,IAAuB,YAAY2B,UAAnC,GACHM,sBAAsB,CAACxE,QAAQ,CAACkE,UAAD,CAAT,CADnB,GAEHO,qBAFJ;;AAIA,eAASA,qBAAT,CAA+BlB,IAA/B,EAAqC;AACnC,YAAIA,IAAI,IAAIW,UAAR,IAAsB,QAAQA,UAAlC,EAA8C;AAC5C,iBAAOM,sBAAsB,CAC3BN,UAAU,CAACQ,IAAX;AACI;AACA1E,UAAAA,QAAQ,CAACkE,UAAU,CAACX,IAAD,CAAX,CAAR,CAA2BoB,MAA3B,CAAkC3E,QAAQ,CAACkE,UAAU,CAACQ,IAAZ,CAA1C,CAFJ,GAGIR,UAAU,CAACX,IAAD,CAJa,CAAtB,CAKLA,IALK,CAAP;AAMD;;AAED,eAAOa,UAAU,CAACb,IAAD,CAAjB;AACD;;AAED,eAASiB,sBAAT,CAAgCI,IAAhC,EAAsC;AACpCP,QAAAA,gBAAgB,GAAGO,IAAnB;AACAN,QAAAA,cAAc,GAAG,CAAjB;AACA,eAAOO,eAAe,CAACD,IAAI,CAACN,cAAD,CAAL,CAAtB;AACD;;AAED,eAASO,eAAT,CAAyBhB,SAAzB,EAAoC;AAClC,eAAOH,KAAP;;AAEA,iBAASA,KAAT,CAAeH,IAAf,EAAqB;AACnB;AACA;AACA;AACA;AACAO,UAAAA,IAAI,GAAGgB,KAAK,EAAZ;AACAP,UAAAA,gBAAgB,GAAGV,SAAnB;;AAEA,cAAI,CAACA,SAAS,CAACkB,OAAf,EAAwB;AACtBlD,YAAAA,OAAO,CAAC0C,gBAAR,GAA2BV,SAA3B;AACD;;AAED,cACEA,SAAS,CAACmB,IAAV,IACAnD,OAAO,CAACtB,MAAR,CAAe2D,UAAf,CAA0Be,OAA1B,CAAkCP,IAAlC,CAAuCQ,OAAvC,CAA+CrB,SAAS,CAACmB,IAAzD,IAAiE,CAAC,CAFpE,EAGE;AACA,mBAAOG,GAAG,EAAV;AACD;;AAED,iBAAOtB,SAAS,CAACtB,QAAV,CAAmBC,IAAnB,CACLiB,MAAM,GAAG7D,MAAM,CAAC,EAAD,EAAKiC,OAAL,EAAc4B,MAAd,CAAT,GAAiC5B,OADlC,EAELX,OAFK,EAGLkE,EAHK,EAILD,GAJK,EAKL5B,IALK,CAAP;AAMD;AACF;;AAED,eAAS6B,EAAT,CAAY7B,IAAZ,EAAkB;AAChBS,QAAAA,QAAQ,CAACO,gBAAD,EAAmBT,IAAnB,CAAR;AACA,eAAOK,WAAP;AACD;;AAED,eAASgB,GAAT,CAAa5B,IAAb,EAAmB;AACjBO,QAAAA,IAAI,CAACC,OAAL;;AAEA,YAAI,EAAEO,cAAF,GAAmBD,gBAAgB,CAACvB,MAAxC,EAAgD;AAC9C,iBAAO+B,eAAe,CAACR,gBAAgB,CAACC,cAAD,CAAjB,CAAtB;AACD;;AAED,eAAOF,UAAP;AACD;AACF;AACF;;AAED,WAASrB,SAAT,CAAmBc,SAAnB,EAA8BpD,IAA9B,EAAoC;AAClC,QAAIoD,SAAS,CAAC1D,UAAV,IAAwBY,oBAAoB,CAACmE,OAArB,CAA6BrB,SAA7B,IAA0C,CAAtE,EAAyE;AACvE9C,MAAAA,oBAAoB,CAAC0B,IAArB,CAA0BoB,SAA1B;AACD;;AAED,QAAIA,SAAS,CAACwB,OAAd,EAAuB;AACrBvF,MAAAA,aAAa,CACX+B,OAAO,CAACE,MADG,EAEXtB,IAFW,EAGXoB,OAAO,CAACE,MAAR,CAAee,MAAf,GAAwBrC,IAHb,EAIXoD,SAAS,CAACwB,OAAV,CAAkBxD,OAAO,CAACE,MAAR,CAAea,KAAf,CAAqBnC,IAArB,CAAlB,EAA8CoB,OAA9C,CAJW,CAAb;AAMD;;AAED,QAAIgC,SAAS,CAACyB,SAAd,EAAyB;AACvBzD,MAAAA,OAAO,CAACE,MAAR,GAAiB8B,SAAS,CAACyB,SAAV,CAAoBzD,OAAO,CAACE,MAA5B,EAAoCF,OAApC,CAAjB;AACD;AACF;;AAED,WAASiD,KAAT,GAAiB;AACf,QAAIS,UAAU,GAAGrD,GAAG,EAApB;AACA,QAAIsD,aAAa,GAAG3D,OAAO,CAACC,QAA5B;AACA,QAAI2D,qBAAqB,GAAG5D,OAAO,CAAC0C,gBAApC;AACA,QAAImB,gBAAgB,GAAG7D,OAAO,CAACE,MAAR,CAAee,MAAtC;AACA,QAAI6C,UAAU,GAAGC,KAAK,CAACnF,IAAN,CAAWQ,KAAX,CAAjB;AACA,WAAO;AACL8C,MAAAA,OAAO,EAAEA,OADJ;AAELtD,MAAAA,IAAI,EAAEiF;AAFD,KAAP;;AAKA,aAAS3B,OAAT,GAAmB;AACjBrD,MAAAA,KAAK,GAAG6E,UAAR;AACA1D,MAAAA,OAAO,CAACC,QAAR,GAAmB0D,aAAnB;AACA3D,MAAAA,OAAO,CAAC0C,gBAAR,GAA2BkB,qBAA3B;AACA5D,MAAAA,OAAO,CAACE,MAAR,CAAee,MAAf,GAAwB4C,gBAAxB;AACAzE,MAAAA,KAAK,GAAG0E,UAAR;AACAzC,MAAAA,uBAAuB;AACxB;AACF;;AAED,WAASA,uBAAT,GAAmC;AACjC,QAAIxC,KAAK,CAACC,IAAN,IAAcG,WAAd,IAA6BJ,KAAK,CAACE,MAAN,GAAe,CAAhD,EAAmD;AACjDF,MAAAA,KAAK,CAACE,MAAN,GAAeE,WAAW,CAACJ,KAAK,CAACC,IAAP,CAA1B;AACAD,MAAAA,KAAK,CAACG,MAAN,IAAgBC,WAAW,CAACJ,KAAK,CAACC,IAAP,CAAX,GAA0B,CAA1C;AACD;AACF;AACF;;AAEDkF,MAAM,CAACC,OAAP,GAAiBxF,eAAjB","sourcesContent":["'use strict'\n\nvar assign = require('../constant/assign.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar chunkedPush = require('./chunked-push.js')\nvar miniflat = require('./miniflat.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar shallow = require('./shallow.js')\nvar resolveAll = require('./resolve-all.js')\nvar serializeChunks = require('./serialize-chunks.js')\nvar sliceChunks = require('./slice-chunks.js')\n\n// Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesn’t receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\nfunction createTokenizer(parser, initialize, from) {\n  var point = from\n    ? shallow(from)\n    : {\n        line: 1,\n        column: 1,\n        offset: 0\n      }\n  var columnStart = {}\n  var resolveAllConstructs = []\n  var chunks = []\n  var stack = []\n\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    })\n  } // State and tools for resolving and serializing.\n\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  } // The state function.\n\n  var state = initialize.tokenize.call(context, effects) // Track which character we expect to be consumed, to catch bugs.\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  } // Store where we are in the input stream.\n\n  point._index = 0\n  point._bufferIndex = -1\n  return context\n\n  function write(slice) {\n    chunks = chunkedPush(chunks, slice)\n    main() // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0) // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  } //\n  // Tools.\n  //\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token))\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  function now() {\n    return shallow(point)\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n  function main() {\n    var chunkIndex\n    var chunk\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index] // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  } // Deal with one code.\n\n  function go(code) {\n    state = state(code)\n  } // Move a character forward.\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    } // Not in a string chunk.\n\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++ // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    } // Expose the previous character.\n\n    context.previous = code // Mark as consumed.\n  } // Start a token.\n\n  function enter(type, fields) {\n    var token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  } // Stop a token.\n\n  function exit(type) {\n    var token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  } // Use results.\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  } // Discard results.\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore()\n  } // Factory to attempt/check/interrupt.\n\n  function constructFactory(onreturn, fields) {\n    return hook // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs\n      var constructIndex\n      var currentConstruct\n      var info\n      return constructs.tokenize || 'length' in constructs\n        ? handleListOfConstructs(miniflat(constructs))\n        : handleMapOfConstructs\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(\n            constructs.null\n              ? /* c8 ignore next */\n                miniflat(constructs[code]).concat(miniflat(constructs.null))\n              : constructs[code]\n          )(code)\n        }\n\n        return bogusState(code)\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        return handleConstruct(list[constructIndex])\n      }\n\n      function handleConstruct(construct) {\n        return start\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.indexOf(construct.name) > -1\n          ) {\n            return nok()\n          }\n\n          return construct.tokenize.call(\n            fields ? assign({}, context, fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      function ok(code) {\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      function nok(code) {\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  function store() {\n    var startPoint = now()\n    var startPrevious = context.previous\n    var startCurrentConstruct = context.currentConstruct\n    var startEventsIndex = context.events.length\n    var startStack = Array.from(stack)\n    return {\n      restore: restore,\n      from: startEventsIndex\n    }\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\nmodule.exports = createTokenizer\n"]},"metadata":{},"sourceType":"script"}