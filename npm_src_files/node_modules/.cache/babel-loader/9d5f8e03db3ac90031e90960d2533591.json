{"ast":null,"code":"'use strict';\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js');\n\nvar factorySpace = require('./factory-space.js');\n\nvar prefixSize = require('../util/prefix-size.js');\n\nvar subtokenize = require('../util/subtokenize.js'); // No name because it must not be turned off.\n\n\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n};\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}; // Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous;\n  return start;\n\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return data;\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    });\n    return data;\n  }\n}\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this;\n  return startLookahead;\n\n  function startLookahead(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    if (self.parser.constructs.disable.null.indexOf('codeIndented') > -1 || prefixSize(self.events, 'linePrefix') < 4) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n    }\n\n    return ok(code);\n  }\n}\n\nmodule.exports = content;","map":{"version":3,"sources":["D:/github/jsonldresume/resume/node_modules/micromark/dist/tokenize/content.js"],"names":["markdownLineEnding","require","factorySpace","prefixSize","subtokenize","content","tokenize","tokenizeContent","resolve","resolveContent","interruptible","lazy","continuationConstruct","tokenizeContinuation","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","parser","constructs","disable","null","indexOf","interrupt","flow","module","exports"],"mappings":"AAAA;;AAEA,IAAIA,kBAAkB,GAAGC,OAAO,CAAC,sCAAD,CAAhC;;AACA,IAAIC,YAAY,GAAGD,OAAO,CAAC,oBAAD,CAA1B;;AACA,IAAIE,UAAU,GAAGF,OAAO,CAAC,wBAAD,CAAxB;;AACA,IAAIG,WAAW,GAAGH,OAAO,CAAC,wBAAD,CAAzB,C,CAEA;;;AACA,IAAII,OAAO,GAAG;AACZC,EAAAA,QAAQ,EAAEC,eADE;AAEZC,EAAAA,OAAO,EAAEC,cAFG;AAGZC,EAAAA,aAAa,EAAE,IAHH;AAIZC,EAAAA,IAAI,EAAE;AAJM,CAAd;AAMA,IAAIC,qBAAqB,GAAG;AAC1BN,EAAAA,QAAQ,EAAEO,oBADgB;AAE1BC,EAAAA,OAAO,EAAE;AAFiB,CAA5B,C,CAGE;AACF;;AAEA,SAASL,cAAT,CAAwBM,MAAxB,EAAgC;AAC9BX,EAAAA,WAAW,CAACW,MAAD,CAAX;AACA,SAAOA,MAAP;AACD;;AAED,SAASR,eAAT,CAAyBS,OAAzB,EAAkCC,EAAlC,EAAsC;AACpC,MAAIC,QAAJ;AACA,SAAOC,KAAP;;AAEA,WAASA,KAAT,CAAeC,IAAf,EAAqB;AACnBJ,IAAAA,OAAO,CAACK,KAAR,CAAc,SAAd;AACAH,IAAAA,QAAQ,GAAGF,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AACvCC,MAAAA,WAAW,EAAE;AAD0B,KAA9B,CAAX;AAGA,WAAOC,IAAI,CAACH,IAAD,CAAX;AACD;;AAED,WAASG,IAAT,CAAcH,IAAd,EAAoB;AAClB,QAAIA,IAAI,KAAK,IAAb,EAAmB;AACjB,aAAOI,UAAU,CAACJ,IAAD,CAAjB;AACD;;AAED,QAAIpB,kBAAkB,CAACoB,IAAD,CAAtB,EAA8B;AAC5B,aAAOJ,OAAO,CAACS,KAAR,CACLb,qBADK,EAELc,eAFK,EAGLF,UAHK,EAILJ,IAJK,CAAP;AAKD,KAXiB,CAWhB;;;AAEFJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACA,WAAOG,IAAP;AACD;;AAED,WAASC,UAAT,CAAoBJ,IAApB,EAA0B;AACxBJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAZ,IAAAA,OAAO,CAACY,IAAR,CAAa,SAAb;AACA,WAAOX,EAAE,CAACG,IAAD,CAAT;AACD;;AAED,WAASM,eAAT,CAAyBN,IAAzB,EAA+B;AAC7BJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAV,IAAAA,QAAQ,GAAGA,QAAQ,CAACW,IAAT,GAAgBb,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AACvDC,MAAAA,WAAW,EAAE,SAD0C;AAEvDJ,MAAAA,QAAQ,EAAEA;AAF6C,KAA9B,CAA3B;AAIA,WAAOK,IAAP;AACD;AACF;;AAED,SAASV,oBAAT,CAA8BG,OAA9B,EAAuCC,EAAvC,EAA2Ca,GAA3C,EAAgD;AAC9C,MAAIC,IAAI,GAAG,IAAX;AACA,SAAOC,cAAP;;AAEA,WAASA,cAAT,CAAwBZ,IAAxB,EAA8B;AAC5BJ,IAAAA,OAAO,CAACK,KAAR,CAAc,YAAd;AACAL,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,YAAb;AACA,WAAO1B,YAAY,CAACc,OAAD,EAAUiB,QAAV,EAAoB,YAApB,CAAnB;AACD;;AAED,WAASA,QAAT,CAAkBb,IAAlB,EAAwB;AACtB,QAAIA,IAAI,KAAK,IAAT,IAAiBpB,kBAAkB,CAACoB,IAAD,CAAvC,EAA+C;AAC7C,aAAOU,GAAG,CAACV,IAAD,CAAV;AACD;;AAED,QACEW,IAAI,CAACG,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,OAApC,CAA4C,cAA5C,IAA8D,CAAC,CAA/D,IACAnC,UAAU,CAAC4B,IAAI,CAAChB,MAAN,EAAc,YAAd,CAAV,GAAwC,CAF1C,EAGE;AACA,aAAOC,OAAO,CAACuB,SAAR,CAAkBR,IAAI,CAACG,MAAL,CAAYC,UAAZ,CAAuBK,IAAzC,EAA+CV,GAA/C,EAAoDb,EAApD,EAAwDG,IAAxD,CAAP;AACD;;AAED,WAAOH,EAAE,CAACG,IAAD,CAAT;AACD;AACF;;AAEDqB,MAAM,CAACC,OAAP,GAAiBrC,OAAjB","sourcesContent":["'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('./factory-space.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar subtokenize = require('../util/subtokenize.js')\n\n// No name because it must not be turned off.\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n}\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n} // Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous\n  return start\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    })\n    return data\n  }\n}\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this\n  return startLookahead\n\n  function startLookahead(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    if (\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1 ||\n      prefixSize(self.events, 'linePrefix') < 4\n    ) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = content\n"]},"metadata":{},"sourceType":"script"}